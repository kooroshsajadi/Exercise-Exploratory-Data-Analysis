{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/kouroshsajjadi/exercise-exploratory-data-analysis?scriptVersionId=143201013\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport glob\n\npath = '../input/building-energy-dataset'\nall_files = glob.glob(path + \"/*.csv\") #Reading all the files\n\nli = []\nfor filename in all_files:\n    df = pd.read_csv(filename, index_col=\"Time\",parse_dates=True, header=0)\n    li.append(df)\n\nbuilding = pd.concat(li, axis=0, ignore_index=False)\nbuilding.sort_index(inplace= True)\n\nbuilding.info()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-16T11:00:02.258806Z","iopub.execute_input":"2023-09-16T11:00:02.259316Z","iopub.status.idle":"2023-09-16T11:06:34.545568Z","shell.execute_reply.started":"2023-09-16T11:00:02.259216Z","shell.execute_reply":"2023-09-16T11:06:34.544153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now resample the data set to an hourly resolution (beware of the units considered)","metadata":{}},{"cell_type":"code","source":"building = building.resample('H').sum() #The obj must have a date-time like index.\nbuilding.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T11:08:01.303806Z","iopub.execute_input":"2023-09-16T11:08:01.304234Z","iopub.status.idle":"2023-09-16T11:08:01.494607Z","shell.execute_reply.started":"2023-09-16T11:08:01.304201Z","shell.execute_reply":"2023-09-16T11:08:01.493141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Below we load the weather data","metadata":{}},{"cell_type":"code","source":"path = '../input/weather-data/Weather_data.csv'\n # use your path\nweather_data = pd.read_csv(path, index_col=\"Datetime\",parse_dates=True, header=0)\ncolumn_names = {'GHI':'Global Horizontal Irradiance [W/m2]', 'DIF':'Diffuse Horizontal Irradiance [W/m2]', 'DNI':'Direct Normal Irradiance [W/m2]', 'SE':'Sun elevation angle [°]', 'SA':'Sun azimuth angle [°]', 'TMOD':'Module temperature [°C]', \n                'TEMP':'Air temperature [°C]', 'WS':'Wind speed [m/s]', 'WD':'Wind direction [°]', 'RH':'Relative humidity [%]', 'AP':' Atmospheric pressure [hPa]', 'PWAT':'Precipitable Water [kg/m2]', 'SWE':'Snow water equivalent [kg/m2]', 'WG':'Wind gust [m/s]'}\nweather_data.rename(columns=column_names, inplace=True)\nweather_data.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-09-16T11:08:08.848225Z","iopub.execute_input":"2023-09-16T11:08:08.848796Z","iopub.status.idle":"2023-09-16T11:08:09.601763Z","shell.execute_reply.started":"2023-09-16T11:08:08.848748Z","shell.execute_reply":"2023-09-16T11:08:09.600722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Then resample weather measurements to hourly values as well.","metadata":{}},{"cell_type":"code","source":"weather_data = weather_data.resample('H').mean()\nweather_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T11:08:13.97524Z","iopub.execute_input":"2023-09-16T11:08:13.975688Z","iopub.status.idle":"2023-09-16T11:08:14.068531Z","shell.execute_reply.started":"2023-09-16T11:08:13.975652Z","shell.execute_reply":"2023-09-16T11:08:14.067006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let us concatenate both data frames together using the pd.concat() function","metadata":{}},{"cell_type":"code","source":"df = pd.concat([building, weather_data], axis=1)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T11:08:17.429292Z","iopub.execute_input":"2023-09-16T11:08:17.43074Z","iopub.status.idle":"2023-09-16T11:08:17.475513Z","shell.execute_reply.started":"2023-09-16T11:08:17.43069Z","shell.execute_reply":"2023-09-16T11:08:17.474599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory data analysis\n\nWith our data set now preprocessed we would like to visually explore a few selected features.\n\n### Run charts\n\nLet us start with a simple runchart of the building energy consumption over a particular year (to not have a plot that is too large).","metadata":{}},{"cell_type":"code","source":"# Select a subset of the building dataframe using the column 'HV power [kW]' and a year of your choosing\nbuilding.info()\ndata_subset = building['HV light Power [kW]'].loc['2016']\nprint(data_subset)","metadata":{"execution":{"iopub.status.busy":"2023-09-16T11:08:21.996675Z","iopub.execute_input":"2023-09-16T11:08:21.998007Z","iopub.status.idle":"2023-09-16T11:08:22.021429Z","shell.execute_reply.started":"2023-09-16T11:08:21.997953Z","shell.execute_reply":"2023-09-16T11:08:22.020514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now plot the subset\nimport matplotlib.pyplot as plt\n\n# Plot the data\nplt.figure(figsize=(10, 6))\nplt.plot(data_subset.index, data_subset.values, label='HV light Power [kW]')\nplt.title('HV Light Power Consumption for 2016')\nplt.xlabel('Date')\nplt.ylabel('Power[kW]')\nplt.legend()\nplt.grid(True)\nplt.xticks(rotation = 45)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T11:08:29.081474Z","iopub.execute_input":"2023-09-16T11:08:29.081887Z","iopub.status.idle":"2023-09-16T11:08:29.400946Z","shell.execute_reply.started":"2023-09-16T11:08:29.081853Z","shell.execute_reply":"2023-09-16T11:08:29.399976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To make things a little more automated to plot multiple years of data, we decide to group them per year and plot them one at a time.","metadata":{}},{"cell_type":"code","source":"#group data by year\ngroups = building['HV light Power [kW]'].groupby(pd.Grouper(freq= 'Y'))","metadata":{"execution":{"iopub.status.busy":"2023-09-16T11:08:36.576803Z","iopub.execute_input":"2023-09-16T11:08:36.577234Z","iopub.status.idle":"2023-09-16T11:08:36.586402Z","shell.execute_reply.started":"2023-09-16T11:08:36.5772Z","shell.execute_reply":"2023-09-16T11:08:36.584805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n#set figure and axis\nfig, axs = plt.subplots(len(groups), 1, figsize=(15,15))\n\n# Loop over groups and plot\nfor ax, (name, group) in zip(axs, groups):\n    \n    ax.plot(pd.Series(group.values))\n    \n    ax.set_xlabel('Hour of Year')\n    ax.set_ylabel('Total Load')\n    ax.set_title(name.year)\n    \n    plt.subplots_adjust(hspace=0.5)","metadata":{"execution":{"iopub.status.busy":"2023-09-16T11:08:38.748568Z","iopub.execute_input":"2023-09-16T11:08:38.749019Z","iopub.status.idle":"2023-09-16T11:08:39.666841Z","shell.execute_reply.started":"2023-09-16T11:08:38.74898Z","shell.execute_reply":"2023-09-16T11:08:39.66541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Correlation heatmap\n\nLet us follow the instructions of https://www.python-graph-gallery.com/91-customize-seaborn-heatmap to plot a correlation heatmap of all our available measurements.","metadata":{}},{"cell_type":"code","source":"# Calculate the correlation matrix of the aggregated dataframe df using a built-in function of pandas\ncorrelation = df# code to complete","metadata":{"execution":{"iopub.status.busy":"2023-09-14T12:49:17.549322Z","iopub.execute_input":"2023-09-14T12:49:17.55005Z","iopub.status.idle":"2023-09-14T12:49:17.557024Z","shell.execute_reply.started":"2023-09-14T12:49:17.549974Z","shell.execute_reply":"2023-09-14T12:49:17.555398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\n\n# Now plot the correlation using the seaborn package as described in under the link\n# code to complete ...","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Going even further we could produce a hierarchical cluster over the correlation matrix as desribed in https://www.python-graph-gallery.com/405-dendrogram-with-heatmap-and-coloured-leaves","metadata":{}},{"cell_type":"code","source":"sns.clustermap(# code to complete ... )\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Heatmaps for time series EDA\n\nLet us follow the steps of described in https://www.python-graph-gallery.com/heatmap-for-timeseries-matplotlib","metadata":{}},{"cell_type":"code","source":"# Select a subset of the data set - over a specific month and year\nsubset = building[ # code to complete ...]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define which feature you would like to visually explore\nfeature = # code to complete ...","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extract hour, day, and temperature\nhour = subset # code to complete ...\nday = subset# code to complete ...\ndata = subset[feature]\n\n# Re-arrange temperature values\ndata = data.values.reshape(24, len(day.unique()), order=\"F\")\n\n# Compute x and y grids, passed to `ax.pcolormesh()`.\n\n# The first + 1 increases the length\n# The outer + 1 ensures days start at 1, and not at 0.\nxgrid = np.arange(day.max() + 1) + 1\n\n# Hours start at 0, length 2\nygrid = np.arange(25)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots()\nax.pcolormesh(xgrid, ygrid, data)\nax.set_frame_on(False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Making this a little more coplex now and plotting this over the months of the year, we get","metadata":{}},{"cell_type":"code","source":"MIN_VAL = building[feature].min()\nMAX_VAL = building[feature].max()\n\ndef single_plot(data, month, year, ax):\n    data = data[(data.index.year == year) & (data.index.month == month)]\n\n    hour = subset # code to complete ...\n    day = subset# code to complete ...\n    temp = data.values.reshape(24, len(day.unique()), order=\"F\")\n    \n    xgrid = np.arange(day.max() + 1) + 1\n    ygrid = np.arange(25)\n    \n    ax.pcolormesh(xgrid, ygrid, temp, cmap=\"magma\", vmin=MIN_VAL, vmax=MAX_VAL)\n    # Invert the vertical axis\n    ax.set_ylim(24, 0)\n    # Set tick positions for both axes\n    ax.yaxis.set_ticks([i for i in range(24)])\n    ax.xaxis.set_ticks([10, 20, 30])\n    # Remove ticks by setting their length to 0\n    ax.yaxis.set_tick_params(length=0)\n    ax.xaxis.set_tick_params(length=0)\n    \n    # Remove all spines\n    ax.set_frame_on(False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"number_of_years_to_plot = # code to complete ...\n\nfig, axes = plt.subplots(number_of_years_to_plot, 12, figsize=(30, 20), sharey=True)\n\nfor i, year in enumerate(range(# ... )):\n    for j, month in enumerate(range(1, 13)):\n        single_plot(building[feature], month, year, axes[i, j])\n\n# Adjust margin and space between subplots\n# Extra space is on the left to add a label\nfig.subplots_adjust(left=0.05, right=0.98, top=0.9, hspace=0.08, wspace=0.04)","metadata":{},"execution_count":null,"outputs":[]}]}