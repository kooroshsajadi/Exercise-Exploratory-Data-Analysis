{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/kouroshsajjadi/smart-buildings-assignment-1?scriptVersionId=143859417\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport glob\nimport missingno as msno\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2023-09-22T09:51:38.764406Z","iopub.execute_input":"2023-09-22T09:51:38.764818Z","iopub.status.idle":"2023-09-22T09:51:40.196954Z","shell.execute_reply.started":"2023-09-22T09:51:38.764787Z","shell.execute_reply":"2023-09-22T09:51:40.195716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Read Building Energy Dataset","metadata":{}},{"cell_type":"code","source":"path = '../input/building-energy-dataset'\n\n# Use glob to get a list of all CSV files in the specified directory\nall_files = glob.glob(path + \"/*.csv\")\n\n# Initialize an empty list to store DataFrames\nli = []\n\n# Loop through each CSV file in the list of file paths\nfor filename in all_files:\n    # Read the CSV file into a DataFrame\n    # - 'filename': The name of the CSV file to be read\n    # - 'index_col=\"Time\"': Set the \"Time\" column as the index of the DataFrame\n    # - 'parse_dates=True': Automatically parse date-like columns as datetime objects\n    # - 'header=0': Use the first row of the CSV file as column headers\n    df = pd.read_csv(filename, index_col=\"Time\", parse_dates=True, header=0)\n    \n    # Append the DataFrame to the list of DataFrames\n    li.append(df)\n\n# Concatenate the list of DataFrames vertically (row-wise) into a single DataFrame\n# - 'pd.concat()': Combine multiple DataFrames into one, stacking them vertically (axis=0)\n# - 'li': List of individual DataFrames to concatenate\n# - 'axis=0': Concatenate vertically\n# - 'ignore_index=False': Preserve the original indices of the DataFrames\nbuilding = pd.concat(li, axis=0, ignore_index=False)\n\n# Optionally, sort the DataFrame by the index if needed\n# - 'building.sort_index()': Sort the DataFrame based on the index (row labels)\n# - 'inplace=True': Apply the sorting operation directly to the 'building' DataFrame\nbuilding.sort_index(inplace=True)\n\n#convert string index into datetime frame by using to_datetime() function\nbuilding.index = pd.to_datetime(building.index,format = \"%d/%m/%Y %H:%M\")","metadata":{"execution":{"iopub.status.busy":"2023-09-22T09:51:40.198947Z","iopub.execute_input":"2023-09-22T09:51:40.19945Z","iopub.status.idle":"2023-09-22T09:52:15.164092Z","shell.execute_reply.started":"2023-09-22T09:51:40.199417Z","shell.execute_reply":"2023-09-22T09:52:15.162576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualize Data","metadata":{}},{"cell_type":"code","source":"# Display information about the concatenated DataFrame\n# - 'building.info()': Print details about the resulting DataFrame, including data types and memory usage\nbuilding.info()\n\nbuilding.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-22T09:52:15.165827Z","iopub.execute_input":"2023-09-22T09:52:15.166179Z","iopub.status.idle":"2023-09-22T09:52:15.259588Z","shell.execute_reply.started":"2023-09-22T09:52:15.16615Z","shell.execute_reply":"2023-09-22T09:52:15.25798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Missingo on the raw data.\nmsno.matrix(building)","metadata":{"execution":{"iopub.status.busy":"2023-09-22T09:52:15.262691Z","iopub.execute_input":"2023-09-22T09:52:15.263075Z","iopub.status.idle":"2023-09-22T09:52:24.48913Z","shell.execute_reply.started":"2023-09-22T09:52:15.263044Z","shell.execute_reply":"2023-09-22T09:52:24.487402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Show info about the total missing data.\nmissing_data = building.isna().sum()\n\n# To calculate the total number of missing values\ntotal_missing = missing_data.sum()\n\n# To calculate the percentage of missing values\npercentage_missing = (total_missing / (building.shape[0] * building.shape[1])) * 100\n\nprint(\"Total Missing Values:\", total_missing)\nprint(\"Percentage of Missing Values:\", percentage_missing, \"%\")","metadata":{"execution":{"iopub.status.busy":"2023-09-22T09:52:24.491082Z","iopub.execute_input":"2023-09-22T09:52:24.491831Z","iopub.status.idle":"2023-09-22T09:52:24.543162Z","shell.execute_reply.started":"2023-09-22T09:52:24.491772Z","shell.execute_reply":"2023-09-22T09:52:24.541873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Report on rows having maximum and minimum missing values.\n\nmax_missing_index = building.isna().sum(axis=1).idxmax()\nmin_missing_index = building.isna().sum(axis=1).idxmin()\n\nprint(\"Index with Maximum Missing Values:\", max_missing_index)\nprint(\"Index with Minimum Missing Values:\", min_missing_index)\n\nmax_missing_row = building.loc[max_missing_index]\nmin_missing_row = building.loc[min_missing_index]\n\nprint(\"\\nRow with maximum missing values.\")\nprint(max_missing_row)\n\nprint(\"\\nRow with minimum missing values.\")\nprint(min_missing_row)\n\n# pd.set_option('display.float_format', '{:.5f}'.format)\n# row_with_values = building[building.notna().all(axis=1)].iloc[2000]\n# print(row_with_values)","metadata":{"execution":{"iopub.status.busy":"2023-09-22T09:52:24.545228Z","iopub.execute_input":"2023-09-22T09:52:24.545659Z","iopub.status.idle":"2023-09-22T09:52:26.42346Z","shell.execute_reply.started":"2023-09-22T09:52:24.545623Z","shell.execute_reply":"2023-09-22T09:52:26.422142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"msno.bar(building)","metadata":{"execution":{"iopub.status.busy":"2023-09-22T09:52:26.424955Z","iopub.execute_input":"2023-09-22T09:52:26.425433Z","iopub.status.idle":"2023-09-22T09:52:27.697585Z","shell.execute_reply.started":"2023-09-22T09:52:26.425386Z","shell.execute_reply":"2023-09-22T09:52:27.696313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Show the missing data on each column.\n\n# Assuming 'building' is your DataFrame\nmissing_data = building.isna().sum()\n\n# Filter out columns with zero missing values\nmissing_data = missing_data[missing_data > 0]\n\n# Calculate the total number of missing values\ntotal_missing = missing_data.sum()\n\n# Calculate the percentage of missing values\npercentage_missing = (total_missing / (building.shape[0] * building.shape[1])) * 100\n\n# Create a bar chart\nplt.figure(figsize=(10, 6))\nbars = plt.bar(missing_data.index, missing_data)\nplt.xlabel('Columns')\nplt.ylabel('Number of Missing Values')\nplt.title('Number of Missing Values by Column')\nplt.xticks(rotation=90)\n\n# Add percentages on top of the bars\nfor bar in bars:\n    yval = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width()/2, yval, f'{yval}\\n{yval/total_missing*100:.2f}%', ha='center', va='bottom', color='black', fontsize=8)\n\n# Add legend for total missing and percentage\nlegend_text = f'Total Missing: {total_missing}\\nPercentage: {percentage_missing:.3f}%'\nplt.legend([legend_text])\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-22T09:52:27.699461Z","iopub.execute_input":"2023-09-22T09:52:27.69988Z","iopub.status.idle":"2023-09-22T09:52:28.058418Z","shell.execute_reply.started":"2023-09-22T09:52:27.699845Z","shell.execute_reply":"2023-09-22T09:52:28.054848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Report on columns having maximum and minimum missing values.\n\nmax_missing_index = building.isna().sum(axis=0).idxmax()\nmin_missing_index = building.isna().sum(axis=0).idxmin()\n\nprint(\"Index with Maximum Missing Values:\", max_missing_index)\nprint(\"Index with Minimum Missing Values:\", min_missing_index)","metadata":{"execution":{"iopub.status.busy":"2023-09-22T09:52:28.060597Z","iopub.execute_input":"2023-09-22T09:52:28.061969Z","iopub.status.idle":"2023-09-22T09:52:28.160374Z","shell.execute_reply.started":"2023-09-22T09:52:28.061912Z","shell.execute_reply":"2023-09-22T09:52:28.158963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot scatter of the missing data\n# Create a scatter plot for missing data\nplt.figure(figsize=(20, 7))  # Set the figure size (optional)\n\n# Iterate through each column\nfor col in building.columns:\n    missing_data = building[col].isnull()\n    if missing_data.any():  # Check if column has any missing values\n        plt.scatter(building.index[missing_data], [col] * missing_data.sum(), marker='x', label=col)\n\nsize = 20\nplt.xlabel('Date', fontsize=size)\nplt.yticks(range(len(building.columns)), building.columns, fontsize=size)\nplt.xticks(fontsize=size)\nplt.title('Missing Data Scatter Plot', fontsize=size)\nplt.grid(True)\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-22T09:52:28.165696Z","iopub.execute_input":"2023-09-22T09:52:28.166136Z","iopub.status.idle":"2023-09-22T09:52:28.776045Z","shell.execute_reply.started":"2023-09-22T09:52:28.1661Z","shell.execute_reply":"2023-09-22T09:52:28.774213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"msno.heatmap(building)","metadata":{"execution":{"iopub.status.busy":"2023-09-22T09:52:28.777635Z","iopub.execute_input":"2023-09-22T09:52:28.77805Z","iopub.status.idle":"2023-09-22T09:52:30.110187Z","shell.execute_reply.started":"2023-09-22T09:52:28.778016Z","shell.execute_reply":"2023-09-22T09:52:30.108879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"msno.dendrogram(building)","metadata":{"execution":{"iopub.status.busy":"2023-09-22T09:52:30.111635Z","iopub.execute_input":"2023-09-22T09:52:30.11203Z","iopub.status.idle":"2023-09-22T09:52:30.901858Z","shell.execute_reply.started":"2023-09-22T09:52:30.111997Z","shell.execute_reply":"2023-09-22T09:52:30.900376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Select rows where either 'feature1' or 'feature2' contains NaN values, 'HV light Power [kW], Power[kW]'\nnan_rows = building[building[['Chiller Power [kW]', 'HVAC Actual [kW]', 'HV light Power [kW]', 'Power[kW]']].isna().all(axis=1)]\n\n# Get the Datetime values for these rows\nnan_dates = nan_rows.index\nprint(len(nan_dates))\n\n# Print the Datetime values with missing values\nprint(\"Datetime values with missing values in either feature1 or feature2:\")\nprint(nan_dates)","metadata":{"execution":{"iopub.status.busy":"2023-09-22T09:52:30.903827Z","iopub.execute_input":"2023-09-22T09:52:30.904287Z","iopub.status.idle":"2023-09-22T09:52:30.968391Z","shell.execute_reply.started":"2023-09-22T09:52:30.904245Z","shell.execute_reply":"2023-09-22T09:52:30.966726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"building_linearly_interpolated = building.interpolate(method='linear')\n\nrow_before_interpolation = building.loc['2016-09-01 15:15:00']\nrow_after_interpolation = building_linearly_interpolated.loc['2016-09-01 15:15:00']\n\n# Create a DataFrame to display the comparison\ncomparison_df = pd.DataFrame({'Before Interpolation': row_before_interpolation, \n                              'After Interpolation': row_after_interpolation})\n\n# Display the comparison table\nprint(comparison_df)\n\nrow_before_interpolation = building.loc['2018-06-05 11:58:00']\nrow_after_interpolation = building_linearly_interpolated.loc['2018-06-05 11:58:00']\n\n# Create a DataFrame to display the comparison\ncomparison_df = pd.DataFrame({'Before Interpolation': row_before_interpolation, \n                              'After Interpolation': row_after_interpolation})\n\n# Display the comparison table\nprint(comparison_df)","metadata":{"execution":{"iopub.status.busy":"2023-09-22T09:52:30.970615Z","iopub.execute_input":"2023-09-22T09:52:30.971809Z","iopub.status.idle":"2023-09-22T09:52:32.181808Z","shell.execute_reply.started":"2023-09-22T09:52:30.971725Z","shell.execute_reply":"2023-09-22T09:52:32.180203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"msno.matrix(building_linearly_interpolated)\n\n# Show info about the total missing data on linearly interpolated data.\nmissing_data = building_linearly_interpolated.isna().sum()\n\n# To calculate the total number of missing values\ntotal_missing = missing_data.sum()\n\n# To calculate the percentage of missing values\npercentage_missing = (total_missing / (building_linearly_interpolated.shape[0] * building_linearly_interpolated.shape[1])) * 100\n\nprint(\"Total Missing Values:\", total_missing)\nprint(\"Percentage of Missing Values:\", percentage_missing, \"%\")","metadata":{"execution":{"iopub.status.busy":"2023-09-22T09:52:32.183708Z","iopub.execute_input":"2023-09-22T09:52:32.184524Z","iopub.status.idle":"2023-09-22T09:52:41.388382Z","shell.execute_reply.started":"2023-09-22T09:52:32.18447Z","shell.execute_reply":"2023-09-22T09:52:41.386933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Weekly line plot.\n\ncolumns_to_plot = ['HVAC Actual [kW]', 'Chiller Power [kW]', 'Humidifier power [kW]', 'HV light Power [kW]', 'Power[kW]']\n\n# Calculate the weekly rolling averages for each column\nweekly_avg = building_linearly_interpolated[columns_to_plot].resample('W').mean()\n\n# Calculate the sum of the power consumption values for each week\nweekly_sum = weekly_avg.sum(axis=1)\n\n# Plot the weekly rolling averages\nplt.figure(figsize=(12, 6))\n\nfor col in columns_to_plot:\n    plt.plot(weekly_avg.index, weekly_avg[col], label=col)\n\n# Add a line for the sum\nplt.plot(weekly_avg.index, weekly_sum, label='Total Power Consumption', color='black', linestyle='dashed')\n\nplt.xlabel('Date')\nplt.ylabel('Power Consumption [kW]')\nplt.title('Weekly Rolling Average Power Consumption')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-22T09:52:41.389946Z","iopub.execute_input":"2023-09-22T09:52:41.390275Z","iopub.status.idle":"2023-09-22T09:52:42.74137Z","shell.execute_reply.started":"2023-09-22T09:52:41.390246Z","shell.execute_reply":"2023-09-22T09:52:42.739659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Weekly bar chart.\n\n# Define the time period (e.g., a specific week)\nstart_date = '2016-09-01'\nend_date = '2016-09-07'\n\n# Filter the data for the specified time period\nperiod_data = building_linearly_interpolated.loc[start_date:end_date]\n\n# Define the columns to plot\ncolumns_to_plot = ['HVAC Actual [kW]', 'Chiller Power [kW]', 'Humidifier power [kW]', 'HV light Power [kW]', 'Power[kW]']\n\n# Plot the bar chart\nplt.figure(figsize=(12, 6))\nplt.bar(columns_to_plot, period_data[columns_to_plot].mean(), color='blue')\nplt.xlabel('Features')\nplt.ylabel('Average Power Consumption [kW]')\nplt.title(f'Average Power Consumption for Week of {start_date} to {end_date}')\nplt.xticks(rotation=45)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-22T09:52:42.743178Z","iopub.execute_input":"2023-09-22T09:52:42.743627Z","iopub.status.idle":"2023-09-22T09:52:43.144154Z","shell.execute_reply.started":"2023-09-22T09:52:42.743584Z","shell.execute_reply":"2023-09-22T09:52:43.142745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Weekly box plot.\n\n# Define the columns to plot\ncolumns_to_plot = ['HVAC Actual [kW]', 'Chiller Power [kW]', 'Humidifier power [kW]', 'HV light Power [kW]', 'Power[kW]']\n\n# Create a box plot\nplt.figure(figsize=(10, 6))\nsns.boxplot(data=building_linearly_interpolated[columns_to_plot])\nplt.xlabel('Features')\nplt.ylabel('Power Consumption [kW]')\nplt.title('Distribution of Power Consumption for Each Feature')\nplt.xticks(rotation=45)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-22T09:52:43.145777Z","iopub.execute_input":"2023-09-22T09:52:43.146161Z","iopub.status.idle":"2023-09-22T09:52:46.10978Z","shell.execute_reply.started":"2023-09-22T09:52:43.146128Z","shell.execute_reply":"2023-09-22T09:52:46.108549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the columns representing energy consumption\nenergy_columns = ['HVAC Actual [kW]', 'Chiller Power [kW]', 'Humidifier power [kW]', 'HV light Power [kW]', 'Power[kW]']\n\n# Resample data by week and calculate the range\nweekly_range = building_linearly_interpolated[energy_columns].resample('W').apply(lambda x: x.max() - x.min())\n\n# Print the range of energy consumption per week\nprint(weekly_range)","metadata":{"execution":{"iopub.status.busy":"2023-09-22T09:52:46.111458Z","iopub.execute_input":"2023-09-22T09:52:46.111852Z","iopub.status.idle":"2023-09-22T09:52:47.766846Z","shell.execute_reply.started":"2023-09-22T09:52:46.111818Z","shell.execute_reply":"2023-09-22T09:52:47.765553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the yearly consumption for each component\nyearly_hvac = building_linearly_interpolated['HVAC Actual [kW]'].resample('Y').sum()\nyearly_chiller = building_linearly_interpolated['Chiller Power [kW]'].resample('Y').sum()\nyearly_humidifier = building_linearly_interpolated['Humidifier power [kW]'].resample('Y').sum()\nyearly_hv_light = building_linearly_interpolated['HV light Power [kW]'].resample('Y').sum()\n\n# Calculate the total Power [kW] for each year\nyearly_total_power = building_linearly_interpolated['Power[kW]'].resample('Y').sum()\n\n# Compare the total Power [kW] with the sum of components\nfor year in yearly_hvac.index:\n    total_power_year = yearly_total_power.loc[year]\n    components_sum = (\n        yearly_hvac.loc[year] +\n        yearly_chiller.loc[year] +\n        yearly_humidifier.loc[year] +\n        yearly_hv_light.loc[year]\n    )\n    print(f'Year {year.year}:')\n    print(f'Total Power [kW]: {total_power_year:.2f}')\n    print(f'Sum of Components: {components_sum:.2f}')\n    print(f'Difference: {total_power_year - components_sum:.2f}\\n')","metadata":{"execution":{"iopub.status.busy":"2023-09-22T10:08:14.56665Z","iopub.execute_input":"2023-09-22T10:08:14.567127Z","iopub.status.idle":"2023-09-22T10:08:17.61392Z","shell.execute_reply.started":"2023-09-22T10:08:14.567093Z","shell.execute_reply":"2023-09-22T10:08:17.612737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#resample the data by daily\nbuilding_day = building_linearly_interpolated.resample('D').mean()","metadata":{"execution":{"iopub.status.busy":"2023-09-22T10:36:47.302391Z","iopub.execute_input":"2023-09-22T10:36:47.302896Z","iopub.status.idle":"2023-09-22T10:36:48.514257Z","shell.execute_reply.started":"2023-09-22T10:36:47.302856Z","shell.execute_reply":"2023-09-22T10:36:48.512696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#select year\nselect_year = 2018\nstart_time = pd.to_datetime(f'{select_year}-1-1')\nend_time = pd.to_datetime(f'{select_year+1}-1-1')\n\n\nbuilding_year_select = building_day.loc[start_time:end_time]\n#building_year_select.head(5)\n\n#extract data of AHU    'HVAC Actual [kW]','Chiller Power [kW]','HV light Power [kW]' ,'Humidifier power [kW]', \nAHU_level_data= building_year_select[['HVAC Actual [kW]','Humidifier power [kW]','Chiller Power [kW]']]\n#AHU_level_data.head()\n#Plot the energy consumption of AHU in a line chart\nplt.figure(figsize=(10, 6))  # Adjust the figure size as needed\n\nfontsize = 15\n\nfor col in AHU_level_data.columns:\n    plt.plot(AHU_level_data.index, AHU_level_data[col], label= col)\n\nplt.title(f'Daily Energy consumption of AHU at component-level performance in {select_year} ',fontsize = fontsize)\nplt.xlabel('Time', fontsize = fontsize)\nplt.ylabel('kW', fontsize = fontsize)\nplt.xticks(fontsize = fontsize)\nplt.yticks(fontsize = fontsize)\n#plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\nplt.legend(fontsize = fontsize)\n\nplt.tight_layout()\nplt.grid()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-22T10:36:50.455051Z","iopub.execute_input":"2023-09-22T10:36:50.45548Z","iopub.status.idle":"2023-09-22T10:36:51.076362Z","shell.execute_reply.started":"2023-09-22T10:36:50.455448Z","shell.execute_reply":"2023-09-22T10:36:51.075039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loop over the selected years (from 2016 to 2021)\nfor select_year in range(2016, 2022):\n    start_time = pd.to_datetime(f'{select_year}-1-1')\n    end_time = pd.to_datetime(f'{select_year+1}-1-1')\n\n    building_year_select = building_day.loc[start_time:end_time]\n\n    # Extract data of AHU\n    AHU_level_data = building_year_select[['HVAC Actual [kW]', 'Humidifier power [kW]', 'Chiller Power [kW]']]\n\n    # Plot the energy consumption of AHU in a line chart\n    plt.figure(figsize=(10, 6))\n\n    for col in AHU_level_data.columns:\n        plt.plot(AHU_level_data.index, AHU_level_data[col], label=col)\n\n    plt.title(f'Daily Energy consumption of AHU at component-level performance in {select_year}', fontsize=fontsize)\n    plt.xlabel('Time', fontsize=fontsize)\n    plt.ylabel('kW', fontsize=fontsize)\n    plt.xticks(fontsize=fontsize)\n    plt.yticks(fontsize=fontsize)\n    plt.legend(fontsize=fontsize)\n\n    plt.tight_layout()\n    plt.grid()\n\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-22T10:20:24.135742Z","iopub.execute_input":"2023-09-22T10:20:24.137242Z","iopub.status.idle":"2023-09-22T10:20:27.571913Z","shell.execute_reply.started":"2023-09-22T10:20:24.137193Z","shell.execute_reply":"2023-09-22T10:20:27.566747Z"},"trusted":true},"execution_count":null,"outputs":[]}]}